{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K3wrjuFuBIzc"
   },
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/how-to-visualize-convolutional-features-in-40-lines-of-code-70b7d87b0030\n",
    "# https://github.com/bckenstler/CLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qIafP8mK1Iac"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aCUSkwF51IY8"
   },
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/22994423/difference-between-np-random-seed-and-np-random-randomstate\n",
    "np.random.seed(18)\n",
    "# np.random.RandomState(18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IOZj89e81IZk"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import os.path as path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "vo3MKYnT1mmt",
    "outputId": "d0d5bffd-20f7-48f7-f5ca-b1eaf63605a8"
   },
   "outputs": [],
   "source": [
    "# # mount gdrive and unzip data\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')\n",
    "# !unzip -q \"/content/gdrive/My Drive/All_Datasets/hvc_data.zip\"\n",
    "# # look for `hvc_annotations.csv` file and `resized` dir\n",
    "# %ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "1DtCtdoz2E30",
    "outputId": "ea37b2e1-6c6f-4517-8f63-af75a3c54604"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Projects\\\\PersonAttributesData'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6rn6ATMl1IaD"
   },
   "outputs": [],
   "source": [
    "project_dir = '.'\n",
    "data_dir = path.join(project_dir,'.')\n",
    "url = path.join(data_dir, 'hvc_annotations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\\.\\hvc_annotations.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(url)\n",
    "path.exists(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "colab_type": "code",
    "id": "oL5l0OXt1Iaz",
    "outputId": "d8784ddf-84de-4d4f-8f45-313732795c7b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>imagequality</th>\n",
       "      <th>age</th>\n",
       "      <th>weight</th>\n",
       "      <th>carryingbag</th>\n",
       "      <th>footwear</th>\n",
       "      <th>emotion</th>\n",
       "      <th>bodypose</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>Average</td>\n",
       "      <td>35-45</td>\n",
       "      <td>normal-healthy</td>\n",
       "      <td>Grocery/Home/Plastic Bag</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Front-Frontish</td>\n",
       "      <td>resized/1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>Average</td>\n",
       "      <td>35-45</td>\n",
       "      <td>over-weight</td>\n",
       "      <td>None</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Angry/Serious</td>\n",
       "      <td>Front-Frontish</td>\n",
       "      <td>resized/2.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender imagequality    age          weight               carryingbag  \\\n",
       "0    male      Average  35-45  normal-healthy  Grocery/Home/Plastic Bag   \n",
       "1  female      Average  35-45     over-weight                      None   \n",
       "\n",
       "  footwear        emotion        bodypose     image_path  \n",
       "0   Normal        Neutral  Front-Frontish  resized/1.jpg  \n",
       "1   Normal  Angry/Serious  Front-Frontish  resized/2.jpg  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(url)\n",
    "df.drop('filename', axis=1, inplace = True)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "HVQcFV6N1IbP",
    "outputId": "641df28f-e628-433f-bb3f-04ed4c7651da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 9)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[:70]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "cXMBt2AC2hEE",
    "outputId": "25e72abb-a481-4cfa-f7bc-455f0fa42367"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13573, 9)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "colab_type": "code",
    "id": "n4uLXuvj1Ibi",
    "outputId": "92389e34-38d4-41e8-d6b9-e5cfd3cae0c1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>image_path</th>\n",
       "      <td>resized/1.jpg</td>\n",
       "      <td>resized/2.jpg</td>\n",
       "      <td>resized/3.jpg</td>\n",
       "      <td>resized/4.jpg</td>\n",
       "      <td>resized/5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender_female</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender_male</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imagequality_Average</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imagequality_Bad</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>imagequality_Good</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_15-25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_25-35</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_35-45</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_45-55</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age_55+</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_normal-healthy</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_over-weight</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_slightly-overweight</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_underweight</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carryingbag_Daily/Office/Work Bag</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carryingbag_Grocery/Home/Plastic Bag</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>carryingbag_None</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>footwear_CantSee</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>footwear_Fancy</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>footwear_Normal</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion_Angry/Serious</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion_Happy</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion_Neutral</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emotion_Sad</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bodypose_Back</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bodypose_Front-Frontish</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bodypose_Side</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  0              1  \\\n",
       "image_path                            resized/1.jpg  resized/2.jpg   \n",
       "gender_female                                     0              1   \n",
       "gender_male                                       1              0   \n",
       "imagequality_Average                              1              1   \n",
       "imagequality_Bad                                  0              0   \n",
       "imagequality_Good                                 0              0   \n",
       "age_15-25                                         0              0   \n",
       "age_25-35                                         0              0   \n",
       "age_35-45                                         1              1   \n",
       "age_45-55                                         0              0   \n",
       "age_55+                                           0              0   \n",
       "weight_normal-healthy                             1              0   \n",
       "weight_over-weight                                0              1   \n",
       "weight_slightly-overweight                        0              0   \n",
       "weight_underweight                                0              0   \n",
       "carryingbag_Daily/Office/Work Bag                 0              0   \n",
       "carryingbag_Grocery/Home/Plastic Bag              1              0   \n",
       "carryingbag_None                                  0              1   \n",
       "footwear_CantSee                                  0              0   \n",
       "footwear_Fancy                                    0              0   \n",
       "footwear_Normal                                   1              1   \n",
       "emotion_Angry/Serious                             0              1   \n",
       "emotion_Happy                                     0              0   \n",
       "emotion_Neutral                                   1              0   \n",
       "emotion_Sad                                       0              0   \n",
       "bodypose_Back                                     0              0   \n",
       "bodypose_Front-Frontish                           1              1   \n",
       "bodypose_Side                                     0              0   \n",
       "\n",
       "                                                  2              3  \\\n",
       "image_path                            resized/3.jpg  resized/4.jpg   \n",
       "gender_female                                     0              0   \n",
       "gender_male                                       1              1   \n",
       "imagequality_Average                              0              0   \n",
       "imagequality_Bad                                  0              0   \n",
       "imagequality_Good                                 1              1   \n",
       "age_15-25                                         0              0   \n",
       "age_25-35                                         0              0   \n",
       "age_35-45                                         0              0   \n",
       "age_45-55                                         1              1   \n",
       "age_55+                                           0              0   \n",
       "weight_normal-healthy                             1              1   \n",
       "weight_over-weight                                0              0   \n",
       "weight_slightly-overweight                        0              0   \n",
       "weight_underweight                                0              0   \n",
       "carryingbag_Daily/Office/Work Bag                 0              1   \n",
       "carryingbag_Grocery/Home/Plastic Bag              1              0   \n",
       "carryingbag_None                                  0              0   \n",
       "footwear_CantSee                                  1              0   \n",
       "footwear_Fancy                                    0              0   \n",
       "footwear_Normal                                   0              1   \n",
       "emotion_Angry/Serious                             0              0   \n",
       "emotion_Happy                                     0              0   \n",
       "emotion_Neutral                                   1              1   \n",
       "emotion_Sad                                       0              0   \n",
       "bodypose_Back                                     0              0   \n",
       "bodypose_Front-Frontish                           1              1   \n",
       "bodypose_Side                                     0              0   \n",
       "\n",
       "                                                  4  \n",
       "image_path                            resized/5.jpg  \n",
       "gender_female                                     1  \n",
       "gender_male                                       0  \n",
       "imagequality_Average                              0  \n",
       "imagequality_Bad                                  0  \n",
       "imagequality_Good                                 1  \n",
       "age_15-25                                         0  \n",
       "age_25-35                                         0  \n",
       "age_35-45                                         1  \n",
       "age_45-55                                         0  \n",
       "age_55+                                           0  \n",
       "weight_normal-healthy                             0  \n",
       "weight_over-weight                                0  \n",
       "weight_slightly-overweight                        1  \n",
       "weight_underweight                                0  \n",
       "carryingbag_Daily/Office/Work Bag                 0  \n",
       "carryingbag_Grocery/Home/Plastic Bag              0  \n",
       "carryingbag_None                                  1  \n",
       "footwear_CantSee                                  1  \n",
       "footwear_Fancy                                    0  \n",
       "footwear_Normal                                   0  \n",
       "emotion_Angry/Serious                             0  \n",
       "emotion_Happy                                     0  \n",
       "emotion_Neutral                                   1  \n",
       "emotion_Sad                                       0  \n",
       "bodypose_Back                                     0  \n",
       "bodypose_Front-Frontish                           1  \n",
       "bodypose_Side                                     0  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoding of labels\n",
    "\n",
    "one_hot_df = pd.concat([\n",
    "    df[[\"image_path\"]],\n",
    "    pd.get_dummies(df.gender, prefix=\"gender\"),\n",
    "    pd.get_dummies(df.imagequality, prefix=\"imagequality\"),\n",
    "    pd.get_dummies(df.age, prefix=\"age\"),\n",
    "    pd.get_dummies(df.weight, prefix=\"weight\"),\n",
    "    pd.get_dummies(df.carryingbag, prefix=\"carryingbag\"),\n",
    "    pd.get_dummies(df.footwear, prefix=\"footwear\"),\n",
    "    pd.get_dummies(df.emotion, prefix=\"emotion\"),\n",
    "    pd.get_dummies(df.bodypose, prefix=\"bodypose\"),\n",
    "], axis = 1)\n",
    "\n",
    "one_hot_df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tmhSQYuV1IcI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13573, 28)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "xD69Apna1Iby",
    "outputId": "557cefd9-b856-4637-e8bf-1985919278e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Projects\\\\PersonAttributesData\\\\processed'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.abspath(path.join(data_dir,'processed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v6_mlB7p1Icp"
   },
   "outputs": [],
   "source": [
    "# Custom batch generator\n",
    "# -------\n",
    "# Good one -  https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\n",
    "# https://towardsdatascience.com/image-augmentation-14a0aafd0498\n",
    "# https://towardsdatascience.com/writing-custom-keras-generators-fe815d992c5a    \n",
    "# https://medium.com/the-artificial-impostor/custom-image-augmentation-with-keras-70595b01aeac\n",
    "# https://towardsdatascience.com/keras-data-generators-and-how-to-use-them-b69129ed779c\n",
    "\n",
    "# Good one - https://www.kaggle.com/nikhilroxtomar/generators-for-keras-model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83
    },
    "colab_type": "code",
    "id": "zjWnBlph1Ic6",
    "outputId": "08e23df2-afeb-4b48-f28c-89fd26215179"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import cv2\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "\n",
    "\n",
    "# Label columns per attribute\n",
    "_gender_cols_ = [col for col in one_hot_df.columns if col.startswith(\"gender\")]\n",
    "_imagequality_cols_ = [col for col in one_hot_df.columns if col.startswith(\"imagequality\")]\n",
    "_age_cols_ = [col for col in one_hot_df.columns if col.startswith(\"age\")]\n",
    "_weight_cols_ = [col for col in one_hot_df.columns if col.startswith(\"weight\")]\n",
    "_carryingbag_cols_ = [col for col in one_hot_df.columns if col.startswith(\"carryingbag\")]\n",
    "_footwear_cols_ = [col for col in one_hot_df.columns if col.startswith(\"footwear\")]\n",
    "_emotion_cols_ = [col for col in one_hot_df.columns if col.startswith(\"emotion\")]\n",
    "_bodypose_cols_ = [col for col in one_hot_df.columns if col.startswith(\"bodypose\")]\n",
    "\n",
    "\n",
    "class PersonDataGenerator(keras.utils.Sequence):\n",
    "    \"\"\"\n",
    "    Ground truth data generator \n",
    "\n",
    "    https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, df, batch_size = 32, input_size = (224, 224), \n",
    "                 location = '.', augmentations = None, save_dir = None,\n",
    "                 shuffle = False):\n",
    "        self.df = df\n",
    "        self.image_size = input_size\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.augmentation = augmentations #ImageDataGenerator instance\n",
    "        self.location = location\n",
    "        self.save_dir =  save_dir # path.abspath(path.join(self.location,'processed'))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "        if self.save_dir:\n",
    "            self.save_dir = path.abspath(self.save_dir)\n",
    "            if not path.isdir(self.save_dir):\n",
    "                os.mkdirs(self.save_dir, exist_ok=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Number of batch in the Sequence.\n",
    "        \"\"\"\n",
    "        return int(np.floor(self.df.shape[0] / self.batch_size))\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Gets batch at position index.\n",
    "        fetch batched images and targets        \n",
    "        \"\"\"\n",
    "        # slice function - https://www.w3schools.com/python/ref_func_slice.asp\n",
    "        \n",
    "        \n",
    "        batch_slice = slice(index * self.batch_size, (index + 1) * self.batch_size)\n",
    "        items = self.df.iloc[batch_slice]\n",
    "\n",
    "        images = np.stack([cv2.imread(path.join(self.location, item[\"image_path\"])) for _, item in items.iterrows()])        \n",
    "#         if self.augmentation:\n",
    "#             if self.save_dir:\n",
    "#                 images = self.augmentation.flow(images, \n",
    "#                                             batch_size=self.batch_size, \n",
    "#                                             save_to_dir=self.save_dir,\n",
    "#                                             save_prefix='aug').next()\n",
    "                    \n",
    "#             else:\n",
    "        images = self.augmentation.flow(images, \n",
    "                                            batch_size=self.batch_size).next()\n",
    "\n",
    "\n",
    "        target = {\n",
    "            \"gender_output\": items[_gender_cols_].values,\n",
    "            \"image_quality_output\": items[_imagequality_cols_].values,\n",
    "            \"age_output\": items[_age_cols_].values,\n",
    "            \"weight_output\": items[_weight_cols_].values,\n",
    "            \"bag_output\": items[_carryingbag_cols_].values,\n",
    "            \"pose_output\": items[_bodypose_cols_].values,\n",
    "            \"footwear_output\": items[_footwear_cols_].values,\n",
    "            \"emotion_output\": items[_emotion_cols_].values,\n",
    "        }\n",
    "        \n",
    "        return images, target\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"\n",
    "        Shuffles/sample the df and thereby \n",
    "        updates indexes after each epoch\n",
    "        \n",
    "        Method called at the end of every epoch.\n",
    "        \n",
    "        \"\"\"\n",
    "        if self.shuffle == True:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "            # frac --> take sample of the given df, sample size is given as fraction number\n",
    "            # reset_index drop --> use the drop parameter to avoid the old index being added as a column\n",
    "            # https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.reset_index.html\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "_JIZuJ9G1IdG",
    "outputId": "00a53571-a98e-42d2-979a-eeb78b688b86"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8143, 28), (5430, 28))"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(one_hot_df, test_size=0.4, random_state=18)\n",
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r1EpK7WT1IdT"
   },
   "outputs": [],
   "source": [
    "def blur(img):\n",
    "    return (cv2.blur(img,(5,5)))\n",
    "\n",
    "def get_random_eraser(input_img, p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\n",
    "    img_h, img_w, img_c = input_img.shape\n",
    "    p_1 = np.random.rand()\n",
    "\n",
    "    if p_1 > p:\n",
    "        return input_img\n",
    "\n",
    "    while True:\n",
    "        s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
    "        r = np.random.uniform(r_1, r_2)\n",
    "        w = int(np.sqrt(s / r))\n",
    "        h = int(np.sqrt(s * r))\n",
    "        left = np.random.randint(0, img_w)\n",
    "        top = np.random.randint(0, img_h)\n",
    "\n",
    "        if left + w <= img_w and top + h <= img_h:\n",
    "            break\n",
    "\n",
    "    if pixel_level:\n",
    "        c = np.random.uniform(v_l, v_h, (h, w, img_c))\n",
    "    else:\n",
    "        c = np.random.uniform(v_l, v_h)\n",
    "\n",
    "    input_img[top:top + h, left:left + w, :] = c\n",
    "\n",
    "    return input_img\n",
    "    \n",
    "\n",
    "def blur_cutout(img):\n",
    "    img =blur(img)\n",
    "    img = get_random_eraser(img)\n",
    "    return img\n",
    "\n",
    "train_aug = ImageDataGenerator(rescale=1/255.0,\n",
    "                                        horizontal_flip=True,\n",
    "                                        rotation_range=30,\n",
    "                                        brightness_range=[0.2,0.8],\n",
    "                                        channel_shift_range=100,\n",
    "                                        preprocessing_function=blur_cutout\n",
    "                                    )\n",
    "\n",
    "val_aug = ImageDataGenerator(rescale=1/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "colab_type": "code",
    "id": "j9bfDyP-1Id2",
    "outputId": "7271a6f9-2f5f-4769-ef1f-abd974faf529"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index :  0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gender': 2,\n",
       " 'image_quality': 3,\n",
       " 'age': 5,\n",
       " 'weight': 4,\n",
       " 'bag': 3,\n",
       " 'pose': 3,\n",
       " 'footwear': 3,\n",
       " 'emotion': 3}"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get number of output units from data\n",
    "images, targets = next(iter(train_gen))\n",
    "num_units = { k.split(\"_output\")[0]:v.shape[1] for k, v in targets.items()}\n",
    "num_units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PersonDataGenerator(keras.utils.Sequence):\n",
    "    def __init__(self, df, batch_size=32, shuffle=True, aug_list=[], incl_orig=True):\n",
    "        self.df = df\n",
    "        self.batch_size=batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "        self.aug_list = aug_list\n",
    "        self.incl_orig = incl_orig\n",
    "        self.orig_len = int(np.floor(self.df.shape[0] / self.batch_size))\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.incl_orig:\n",
    "            delta = 1\n",
    "        else:\n",
    "            delta = 0\n",
    "#         print('values of self.df.shape[0], self.batch_size,  self.orig_len, len(self.aug_list), delta', self.df.shape[0], self.batch_size,  self.orig_len, len(self.aug_list), delta)\n",
    "#         print('len : ', self.orig_len * (len(self.aug_list) + delta))\n",
    "        return self.orig_len * (len(self.aug_list) + delta)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if not self.incl_orig :\n",
    "            index += self.orig_len - 1\n",
    "\n",
    "#         print('Index : ', index)\n",
    "#         print('self.orig_len : ', self.orig_len)\n",
    "        \n",
    "        if index > self.orig_len - 1:\n",
    "            aug = self.aug_list[index // self.orig_len - 1]\n",
    "            index %= self.orig_len\n",
    "#             print('Inside if condition - aug_ele : ', (index // self.orig_len - 1), self.aug_list[index // self.orig_len - 1])\n",
    "        else:\n",
    "            aug = None\n",
    "\n",
    "#         print('Index : ', index)\n",
    "        \n",
    "        batch_slice = slice(index * self.batch_size, (index + 1) * self.batch_size)\n",
    "        items = self.df.iloc[batch_slice]\n",
    "        \n",
    "        images = np.stack([cv2.imread(item[\"image_path\"]) for _, item in items.iterrows()])        \n",
    "        \n",
    "        if aug is not None:\n",
    "            images = aug.flow(images, shuffle=False).next()\n",
    "#             print('Augmentation is done')\n",
    "        \n",
    "        target = {\n",
    "            \"gender_output\": items[_gender_cols_].values,\n",
    "            \"image_quality_output\": items[_imagequality_cols_].values,\n",
    "            \"age_output\": items[_age_cols_].values,\n",
    "            \"weight_output\": items[_weight_cols_].values,\n",
    "            \"bag_output\": items[_carryingbag_cols_].values,\n",
    "            \"pose_output\": items[_bodypose_cols_].values,\n",
    "            \"footwear_output\": items[_footwear_cols_].values,\n",
    "            \"emotion_output\": items[_emotion_cols_].values,\n",
    "        }\n",
    "        \n",
    "        return images, target\n",
    "    def on_epoch_end(\n",
    "self):\n",
    "        \"\"\"Updates indexes after each epoch\"\"\"\n",
    "        if self.shuffle == True:\n",
    "            self.df = self.df.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = PersonDataGenerator(\n",
    "    train_df, \n",
    "    batch_size=32, \n",
    "    aug_list=[\n",
    "        ImageDataGenerator(rotation_range=45),\n",
    "        ImageDataGenerator(horizontal_flip=True),\n",
    "        ImageDataGenerator(vertical_flip=True),\n",
    "    ],\n",
    "    incl_orig=True,  # Whether to include original images\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1016"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x23650788940>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_gen[1000][0][0])\n",
    "# train_gen[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values of self.df.shape[0], self.batch_size,  self.orig_len, len(self.aug_list), delta 8143 32 254 3 1\n",
      "len :  1016\n",
      "Index :  0\n",
      "self.orig_len :  254\n",
      "Index :  0\n"
     ]
    }
   ],
   "source": [
    "images_ge, targets = next(iter(train_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values of self.df.shape[0], self.batch_size,  self.orig_len, len(self.aug_list), delta 8143 32 254 3 0\n",
      "Index :  253\n",
      "self.orig_len :  254\n",
      "Index :  253\n"
     ]
    }
   ],
   "source": [
    "images_ge, targets = next(iter(train_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_ge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Baseline_Overfitting_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
